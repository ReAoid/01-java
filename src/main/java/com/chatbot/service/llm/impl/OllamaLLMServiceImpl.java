package com.chatbot.service.llm.impl;

import com.chatbot.config.AppConfig;
import com.chatbot.model.dto.llm.OllamaChatRequest;
import com.chatbot.model.dto.common.ApiResult;
import com.chatbot.model.dto.common.HealthCheckResult;
import com.chatbot.model.dto.llm.*;
import com.chatbot.service.llm.LLMService;
import com.chatbot.util.JsonUtil;
import com.fasterxml.jackson.databind.JsonNode;
import okhttp3.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.TimeUnit;
import java.util.function.Consumer;

/**
 * Ollama LLMæœåŠ¡å®ç°
 * å®ç°LLMServiceæ¥å£ï¼Œå¯¹æ¥Ollamaæœ¬åœ°LLMæœåŠ¡
 * 
 * è®¾è®¡æ¨¡å¼ï¼š
 * - é€‚é…å™¨æ¨¡å¼ï¼šå°†Ollama APIé€‚é…ä¸ºç»Ÿä¸€çš„LLMServiceæ¥å£
 * - é—¨é¢æ¨¡å¼ï¼šç®€åŒ–Ollama APIçš„å¤æ‚è°ƒç”¨
 */
@Service("ollamaLLMService")
public class OllamaLLMServiceImpl implements LLMService {

    private static final Logger logger = LoggerFactory.getLogger(OllamaLLMServiceImpl.class);

    private final AppConfig.OllamaConfig ollamaConfig;
    private final OkHttpClient httpClient;

    // å¥åº·æ£€æŸ¥ç¼“å­˜
    private volatile boolean serviceAvailable = false;
    private volatile long lastHealthCheck = 0;
    private static final long HEALTH_CHECK_CACHE_MS = 30 * 1000; // 30ç§’

    public OllamaLLMServiceImpl(AppConfig appConfig) {
        this.ollamaConfig = appConfig.getOllama();

        // é…ç½®HTTPå®¢æˆ·ç«¯
        this.httpClient = new OkHttpClient.Builder()
                .connectTimeout(10, TimeUnit.SECONDS)
                .readTimeout(120, TimeUnit.SECONDS)
                .writeTimeout(15, TimeUnit.SECONDS)
                .connectionPool(new ConnectionPool(10, 5, TimeUnit.MINUTES))
                .retryOnConnectionFailure(true)
                .build();

        logger.info("Ollama LLMæœåŠ¡å®ç°åˆå§‹åŒ–å®Œæˆï¼Œå¼•æ“: Ollama, URL: {}", ollamaConfig.getChatUrl());

        // å¯åŠ¨æ—¶è¿›è¡Œä¸€æ¬¡å¥åº·æ£€æŸ¥
        healthCheck();
    }

    @Override
    public String getEngineName() {
        return "Ollama";
    }

    @Override
    public HealthCheckResult healthCheck() {
        long startTime = System.currentTimeMillis();

        // ä½¿ç”¨ç¼“å­˜é¿å…é¢‘ç¹æ£€æŸ¥
        if (System.currentTimeMillis() - lastHealthCheck < HEALTH_CHECK_CACHE_MS) {
            return new HealthCheckResult.Builder()
                    .serviceName(getEngineName())
                    .healthy(serviceAvailable)
                    .status(serviceAvailable ? "AVAILABLE" : "UNAVAILABLE")
                    .responseTime(0)
                    .detail("cached", "ä½¿ç”¨ç¼“å­˜ç»“æœ")
                    .build();
        }

        try {
            Request request = new Request.Builder()
                    .url(ollamaConfig.getModelsUrl())
                    .get()
                    .build();

            try (Response response = httpClient.newCall(request).execute()) {
                long responseTime = System.currentTimeMillis() - startTime;
                serviceAvailable = response.isSuccessful();
                lastHealthCheck = System.currentTimeMillis();

                if (serviceAvailable) {
                    logger.debug("Ollama LLMæœåŠ¡å¥åº·æ£€æŸ¥æˆåŠŸï¼Œå“åº”æ—¶é—´: {}ms", responseTime);

                    return new HealthCheckResult.Builder()
                            .serviceName(getEngineName())
                            .healthy(true)
                            .status("AVAILABLE")
                            .responseTime(responseTime)
                            .detail("url", ollamaConfig.getChatUrl())
                            .detail("model", ollamaConfig.getModel())
                            .build();
                } else {
                    logger.warn("Ollama LLMæœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {}", response.code());

                    return new HealthCheckResult.Builder()
                            .serviceName(getEngineName())
                            .healthy(false)
                            .status("UNAVAILABLE")
                            .responseTime(responseTime)
                            .detail("error", "HTTP " + response.code())
                            .build();
                }
            }
        } catch (Exception e) {
            long responseTime = System.currentTimeMillis() - startTime;
            serviceAvailable = false;
            lastHealthCheck = System.currentTimeMillis();

            logger.error("Ollama LLMæœåŠ¡å¥åº·æ£€æŸ¥å¼‚å¸¸", e);

            return new HealthCheckResult.Builder()
                    .serviceName(getEngineName())
                    .healthy(false)
                    .status("ERROR")
                    .responseTime(responseTime)
                    .detail("error", e.getMessage())
                    .build();
        }
    }

    @Override
    public ApiResult<LLMResponse> generate(LLMRequest request) {
        try {
            // éªŒè¯è¯·æ±‚
            ApiResult<Void> validation = validateRequest(request);
            if (!validation.isSuccess()) {
                return ApiResult.failure(validation.getErrorCode(), validation.getMessage());
            }

            // æ„å»ºOllamaè¯·æ±‚
            String requestBody = buildRequestJson(request);
            String url = ollamaConfig.getChatUrl();

            Request httpRequest = new Request.Builder()
                    .url(url)
                    .post(RequestBody.create(requestBody, MediaType.parse("application/json")))
                    .build();

            logger.info("ğŸ¤– å‘é€LLMéæµå¼è¯·æ±‚ - æ¨¡å‹: {}, æ¶ˆæ¯æ•°: {}", request.getModel(), request.getMessages().size());

            long startTime = System.currentTimeMillis();

            try (Response response = httpClient.newCall(httpRequest).execute()) {
                long durationMs = System.currentTimeMillis() - startTime;

                if (!response.isSuccessful()) {
                    String errorMsg = "Ollama APIè¿”å›é”™è¯¯: " + response.code();
                    logger.error("âŒ {}", errorMsg);
                    return ApiResult.failure("LLM_ERROR", errorMsg);
                }

                ResponseBody responseBody = response.body();
                if (responseBody == null) {
                    return ApiResult.failure("EMPTY_RESPONSE", "å“åº”ä½“ä¸ºç©º");
                }

                String responseText = responseBody.string();
                LLMResponse llmResponse = parseResponse(responseText, request.getModel(), durationMs);

                logger.info("âœ… LLMéæµå¼å“åº”å®Œæˆï¼Œå†…å®¹é•¿åº¦: {}, è€—æ—¶: {}ms", llmResponse.getContent().length(), durationMs);

                return ApiResult.success(llmResponse);
            }
        } catch (IOException e) {
            logger.error("âŒ LLMè¯·æ±‚å¼‚å¸¸", e);
            return ApiResult.failure("IO_ERROR", "ç½‘ç»œè¯·æ±‚å¤±è´¥: " + e.getMessage());
        } catch (Exception e) {
            logger.error("âŒ LLMå¤„ç†å¼‚å¸¸", e);
            return ApiResult.failure("PROCESSING_ERROR", "å¤„ç†å¤±è´¥: " + e.getMessage());
        }
    }

    @Override
    public CompletableFuture<ApiResult<LLMResponse>> generateAsync(LLMRequest request) {
        return CompletableFuture.supplyAsync(() -> generate(request));
    }

    @Override
    public Object generateStream(
            LLMRequest request,
            Consumer<LLMStreamChunk> onChunk,
            Consumer<Throwable> onError,
            Runnable onComplete) {
        return generateStreamWithInterruptCheck(request, onChunk, onError, onComplete, null);
    }

    @Override
    public Object generateStreamWithInterruptCheck(
            LLMRequest request,
            Consumer<LLMStreamChunk> onChunk,
            Consumer<Throwable> onError,
            Runnable onComplete,
            java.util.function.Supplier<Boolean> interruptChecker) {

        // éªŒè¯è¯·æ±‚
        ApiResult<Void> validation = validateRequest(request);
        if (!validation.isSuccess()) {
            onError.accept(new IllegalArgumentException(validation.getMessage()));
            return null;
        }

        try {
            // æ„å»ºOllamaè¯·æ±‚
            String requestBody = buildRequestJson(request);
            String url = ollamaConfig.getChatUrl();

            Request httpRequest = new Request.Builder()
                    .url(url)
                    .post(RequestBody.create(requestBody, MediaType.parse("application/json")))
                    .build();

            logger.info("ğŸ¤– å‘é€LLMæµå¼è¯·æ±‚ - æ¨¡å‹: {}, æ¶ˆæ¯æ•°: {}", request.getModel(), request.getMessages().size());

            // å¼‚æ­¥æ‰§è¡Œè¯·æ±‚
            okhttp3.Call call = httpClient.newCall(httpRequest);
            call.enqueue(new Callback() {
                @Override
                public void onFailure(Call call, IOException e) {
                    logger.error("âŒ LLMæµå¼è¯·æ±‚å¤±è´¥: {}", e.getMessage());
                    onError.accept(e);
                }

                @Override
                public void onResponse(Call call, Response response) throws IOException {
                    if (!response.isSuccessful()) {
                        String errorMsg = "LLM APIè¿”å›é”™è¯¯: " + response.code();
                        logger.error("âŒ {}", errorMsg);
                        onError.accept(new RuntimeException(errorMsg));
                        return;
                    }

                    logger.info("âœ… LLMæµå¼å“åº”å¼€å§‹ - çŠ¶æ€ç : {}", response.code());

                    try (ResponseBody responseBody = response.body()) {
                        if (responseBody == null) {
                            onError.accept(new RuntimeException("å“åº”ä½“ä¸ºç©º"));
                            return;
                        }

                        // å¤„ç†æµå¼å“åº”
                        processStreamingResponse(responseBody, request.getModel(), onChunk, onError, onComplete, interruptChecker);
                    }
                }
            });

            return call;

        } catch (Exception e) {
            logger.error("âŒ æ„å»ºLLMè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯", e);
            onError.accept(e);
            return null;
        }
    }

    @Override
    public ApiResult<List<ModelInfo>> getAvailableModels() {
        try {
            Request request = new Request.Builder()
                    .url(ollamaConfig.getModelsUrl())
                    .get()
                    .build();

            try (Response response = httpClient.newCall(request).execute()) {
                if (!response.isSuccessful()) {
                    return ApiResult.failure("API_ERROR", "æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: HTTP " + response.code());
                }

                ResponseBody responseBody = response.body();
                if (responseBody == null) {
                    return ApiResult.failure("EMPTY_RESPONSE", "å“åº”ä½“ä¸ºç©º");
                }

                String responseText = responseBody.string();
                List<ModelInfo> models = parseModelsResponse(responseText);

                return ApiResult.success(models);
            }
        } catch (Exception e) {
            logger.error("è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¤±è´¥", e);
            return ApiResult.failure("ERROR", "è·å–å¤±è´¥: " + e.getMessage());
        }
    }

    @Override
    public ApiResult<ModelInfo> getModelInfo(String modelName) {
        ApiResult<List<ModelInfo>> modelsResult = getAvailableModels();
        if (!modelsResult.isSuccess()) {
            return ApiResult.failure(modelsResult.getErrorCode(), modelsResult.getMessage());
        }

        List<ModelInfo> models = modelsResult.getData();
        for (ModelInfo model : models) {
            if (model.getName().equals(modelName)) {
                return ApiResult.success(model);
            }
        }

        return ApiResult.failure("NOT_FOUND", "æœªæ‰¾åˆ°æ¨¡å‹: " + modelName);
    }

    @Override
    public boolean isServiceAvailable() {
        // ä½¿ç”¨ç¼“å­˜çš„å¥åº·æ£€æŸ¥ç»“æœ
        if (System.currentTimeMillis() - lastHealthCheck < HEALTH_CHECK_CACHE_MS) {
            return serviceAvailable;
        }

        // æ‰§è¡Œæ–°çš„å¥åº·æ£€æŸ¥
        HealthCheckResult result = healthCheck();
        return result.isHealthy();
    }

    @Override
    public ApiResult<Void> validateRequest(LLMRequest request) {
        if (request == null) {
            return ApiResult.failure("INVALID_REQUEST", "è¯·æ±‚ä¸èƒ½ä¸ºç©º");
        }

        if (request.getMessages() == null || request.getMessages().isEmpty()) {
            return ApiResult.failure("INVALID_REQUEST", "æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º");
        }

        if (request.getModel() == null || request.getModel().trim().isEmpty()) {
            return ApiResult.failure("INVALID_REQUEST", "æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º");
        }

        if (request.getTemperature() != null && (request.getTemperature() < 0 || request.getTemperature() > 2)) {
            return ApiResult.failure("INVALID_REQUEST", "æ¸©åº¦å‚æ•°å¿…é¡»åœ¨0-2ä¹‹é—´");
        }

        return ApiResult.success(null);
    }

    @Override
    public ApiResult<Integer> estimateTokens(LLMRequest request) {
        if (request == null || request.getMessages() == null) {
            return ApiResult.failure("INVALID_REQUEST", "è¯·æ±‚ä¸èƒ½ä¸ºç©º");
        }

        // ç®€å•ä¼°ç®—ï¼šæ¯ä¸ªå­—ç¬¦çº¦0.4ä¸ªtokenï¼ˆä¸­æ–‡ï¼‰ï¼Œæ¯ä¸ªå•è¯çº¦1ä¸ªtokenï¼ˆè‹±æ–‡ï¼‰
        int totalChars = 0;
        for (var message : request.getMessages()) {
            if (message.getContent() != null) {
                totalChars += message.getContent().length();
            }
        }

        // ç²—ç•¥ä¼°ç®—
        int estimatedTokens = (int) (totalChars * 0.5);

        return ApiResult.success(estimatedTokens);
    }

    // ========== ç§æœ‰è¾…åŠ©æ–¹æ³• ==========

    /**
     * è½¬æ¢é€šç”¨ Message ä¸º OllamaMessage
     * å®ç°ç»Ÿä¸€æ¥å£å±‚åˆ° Ollama å®ç°å±‚çš„é€‚é…
     */
    private List<OllamaMessage> convertToOllamaMessages(List<Message> messages) {
        if (messages == null) {
            return new ArrayList<>();
        }
        
        List<OllamaMessage> ollamaMessages = new ArrayList<>();
        for (Message message : messages) {
            ollamaMessages.add(new OllamaMessage(message.getRole(), message.getContent()));
        }
        
        return ollamaMessages;
    }
    
    /**
     * è½¬æ¢ OllamaMessage ä¸ºé€šç”¨ Message
     * ç”¨äºå‘ä¸Šå±‚è¿”å›æ•°æ®æ—¶çš„è½¬æ¢
     */
    private List<Message> convertFromOllamaMessages(List<OllamaMessage> ollamaMessages) {
        if (ollamaMessages == null) {
            return new ArrayList<>();
        }
        
        List<Message> messages = new ArrayList<>();
        for (OllamaMessage ollamaMessage : ollamaMessages) {
            messages.add(new Message(ollamaMessage.getRole(), ollamaMessage.getContent()));
        }
        
        return messages;
    }

    /**
     * æ„å»ºOllamaè¯·æ±‚JSON
     */
    private String buildRequestJson(LLMRequest request) {
        try {
            // å°†ç»Ÿä¸€æ¥å£å±‚çš„ Message è½¬æ¢ä¸º Ollama ç‰¹å®šçš„ OllamaMessage
            List<OllamaMessage> ollamaMessages = convertToOllamaMessages(request.getMessages());
            
            OllamaChatRequest ollamaRequest = OllamaChatRequest.fromMessages(
                    request.getModel(),
                    ollamaMessages,
                    request.isStream(),
                    request.getTemperature() != null ? request.getTemperature() : ollamaConfig.getTemperature()
            );

            return JsonUtil.toJson(ollamaRequest);
        } catch (Exception e) {
            logger.error("æ„å»ºè¯·æ±‚JSONå¤±è´¥", e);
            throw new RuntimeException("æ„å»ºè¯·æ±‚å¤±è´¥", e);
        }
    }

    /**
     * è§£æéæµå¼å“åº”
     */
    private LLMResponse parseResponse(String responseText, String model, long durationMs) {
        try {
            JsonNode jsonNode = JsonUtil.parseJson(responseText);
            if (jsonNode == null) {
                return new LLMResponse.Builder()
                        .content("è§£æå“åº”å¤±è´¥")
                        .model(model)
                        .durationMs(durationMs)
                        .build();
            }

            // æå–å†…å®¹
            String content = "";
            JsonNode messageNode = jsonNode.get("message");
            if (messageNode != null) {
                content = JsonUtil.getStringValue(messageNode, "content");
            }

            // æå–tokenä¿¡æ¯
            Integer promptTokensObj = JsonUtil.getIntValue(jsonNode, "prompt_eval_count");
            Integer completionTokensObj = JsonUtil.getIntValue(jsonNode, "eval_count");
            int promptTokens = promptTokensObj != null ? promptTokensObj : 0;
            int completionTokens = completionTokensObj != null ? completionTokensObj : 0;
            int totalTokens = promptTokens + completionTokens;

            Boolean done = JsonUtil.getBooleanValue(jsonNode, "done");

            return new LLMResponse.Builder()
                    .content(content != null ? content : "")
                    .model(model)
                    .done(done != null ? done : true)
                    .promptTokens(promptTokens)
                    .completionTokens(completionTokens)
                    .totalTokens(totalTokens)
                    .durationMs(durationMs)
                    .build();

        } catch (Exception e) {
            logger.error("è§£æLLMå“åº”å¤±è´¥", e);
            return new LLMResponse.Builder()
                    .content("è§£æå“åº”å¤±è´¥: " + e.getMessage())
                    .model(model)
                    .durationMs(durationMs)
                    .build();
        }
    }

    /**
     * å¤„ç†æµå¼å“åº”
     */
    private void processStreamingResponse(
            ResponseBody responseBody,
            String model,
            Consumer<LLMStreamChunk> onChunk,
            Consumer<Throwable> onError,
            Runnable onComplete,
            java.util.function.Supplier<Boolean> interruptChecker) {

        int chunkIndex = 0;
        boolean hasContent = false;

        try {
            try (var source = responseBody.source()) {
                String line;
                while ((line = source.readUtf8Line()) != null) {
                    // æ£€æŸ¥ä¸­æ–­
                    if (interruptChecker != null && interruptChecker.get()) {
                        logger.info("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢å¤„ç†LLMæµå¼å“åº”");
                        return;
                    }

                    if (line.trim().isEmpty()) {
                        continue;
                    }

                    try {
                        JsonNode jsonNode = JsonUtil.parseJson(line);
                        if (jsonNode == null) {
                            continue;
                        }

                        // æ£€æŸ¥é”™è¯¯
                        String error = JsonUtil.getStringValue(jsonNode, "error");
                        if (error != null && !error.isEmpty()) {
                            logger.error("Ollamaè¿”å›é”™è¯¯: {}", error);
                            onError.accept(new RuntimeException("LLM APIé”™è¯¯: " + error));
                            return;
                        }

                        // æ£€æŸ¥å®Œæˆ
                        Boolean done = JsonUtil.getBooleanValue(jsonNode, "done");
                        if (done != null && done) {
                            logger.debug("LLMæµå¼å“åº”å®Œæˆä¿¡å·æ¥æ”¶");
                            break;
                        }

                        // æå–å†…å®¹
                        JsonNode messageNode = jsonNode.get("message");
                        if (messageNode != null) {
                            String content = JsonUtil.getStringValue(messageNode, "content");
                            if (content != null && !content.isEmpty()) {
                                hasContent = true;

                                LLMStreamChunk chunk = new LLMStreamChunk.Builder()
                                        .content(content)
                                        .model(model)
                                        .done(false)
                                        .chunkIndex(chunkIndex++)
                                        .build();

                                onChunk.accept(chunk);
                            }
                        }

                    } catch (Exception e) {
                        logger.warn("è§£ææµå¼å“åº”è¡Œå¤±è´¥: {}", line, e);
                    }
                }

                // å‘é€å®Œæˆå—
                if (hasContent) {
                    LLMStreamChunk finalChunk = new LLMStreamChunk.Builder()
                            .content("")
                            .model(model)
                            .done(true)
                            .chunkIndex(chunkIndex)
                            .build();

                    onChunk.accept(finalChunk);
                }

                logger.info("ğŸ“Š LLMæµå¼å“åº”å®Œæˆ - æ•°æ®å—: {}", chunkIndex);

                // è°ƒç”¨å®Œæˆå›è°ƒ
                if (onComplete != null) {
                    onComplete.run();
                }
            }

        } catch (Exception e) {
            logger.error("å¤„ç†LLMæµå¼å“åº”æ—¶å‘ç”Ÿé”™è¯¯", e);
            onError.accept(e);
        } finally {
            try {
                responseBody.close();
            } catch (Exception e) {
                logger.debug("å…³é—­å“åº”ä½“æ—¶å‡ºç°å¼‚å¸¸", e);
            }
        }
    }

    /**
     * è§£ææ¨¡å‹åˆ—è¡¨å“åº”
     */
    private List<ModelInfo> parseModelsResponse(String responseText) {
        List<ModelInfo> models = new ArrayList<>();

        try {
            JsonNode jsonNode = JsonUtil.parseJson(responseText);
            if (jsonNode == null || !jsonNode.has("models")) {
                return models;
            }

            JsonNode modelsNode = jsonNode.get("models");
            if (modelsNode.isArray()) {
                for (JsonNode modelNode : modelsNode) {
                    String name = JsonUtil.getStringValue(modelNode, "name");
                    if (name != null) {
                        // è§£ææ¨¡å‹åç§°ï¼Œå¦‚ "yi:6b" -> family="yi", size="6b"
                        String[] parts = name.split(":");
                        String family = parts.length > 0 ? parts[0] : name;
                        String size = parts.length > 1 ? parts[1] : "unknown";

                        ModelInfo model = new ModelInfo.Builder()
                                .name(name)
                                .displayName(name)
                                .family(family)
                                .size(size)
                                .available(true)
                                .build();

                        models.add(model);
                    }
                }
            }
        } catch (Exception e) {
            logger.error("è§£ææ¨¡å‹åˆ—è¡¨å¤±è´¥", e);
        }

        return models;
    }
}

